{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-openai langchain-community chromadb langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install -q python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Select an embeddings model\n",
    "#################################################################\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  pip install chromadb\n",
    "# https://python.langchain.com/docs/integrations/vectorstores/chroma#passing-a-chroma-client-into-langchain\n",
    "\n",
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chromadb\")\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    # persist_directory=\"./chromadb\",  # by default it is memory only\n",
    "    collection_name=\"my_langchain\",  # the default chromadb collection is langchain\n",
    "    client=chroma_client,\n",
    "    embedding_function=embeddings,  # different from  Chroma.from_documents\n",
    "    # https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain_community/vectorstores/chroma.py\n",
    "    # client_settings\n",
    ")\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "# docs = retriever.get_relevant_documents(\"What is devopsdays?\")\n",
    "# print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#################################################################\n",
    "# Get a predefined prompt for RAG\n",
    "# from the langchain hub\n",
    "# https://smith.langchain.com/hub\n",
    "#################################################################\n",
    "\n",
    "# needs pip install langchainhub\n",
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's inspect the prompt we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['context', 'question']\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: some question \n",
      "Context: some context \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(prompt.input_variables)\n",
    "a=prompt.format_prompt(context=\"some context\",question=\"some question\")\n",
    "for msg in a.messages:\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a Chat LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# helper function to join a set of documents\n",
    "# Retrieved from the vectorstore\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devopsdays is a worldwide series of technical conferences that cover topics of software development, IT infrastructure operations, and the intersection between them. These events are run by volunteers from the local area and often include curated talks and self-organized open space content. Topics discussed at Devopsdays events include automation, testing, security, and organizational culture.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#################################################################\n",
    "# Setup our rag chain\n",
    "# Using LCEL : Langchain  Expression Language\n",
    "# https://python.langchain.com/docs/expression_language/\n",
    "#################################################################\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | chat\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "answer = rag_chain.invoke(\"What is Devopsdays ?\")\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-llms-and-genai-for-dev-sec-ops-Sv6v5t2W-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
