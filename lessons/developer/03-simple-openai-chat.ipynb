{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try a different kind of LLM: a chat oriented model. The different between the previous llm is that these chat llms have been specifially train on completing chats, where the others are more generic.\n",
    "\n",
    "The related Langchain example page : <https://python.langchain.com/docs/modules/model_io/models/chat/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# First install langchain , openai\n",
    "%pip install -q langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install -q python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize a chat model instead of a regular LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat models typically operate using a set of messages they send to the LLM.\n",
    "- The System message is what sets the tone or the initial behavior of the model\n",
    "- The Human message that asks the question\n",
    "- The AI Message that is the response of the AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"J'adore la programmation.\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    HumanMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessage(content=\"I love programming.\")\n",
    "]\n",
    "answer = chat.invoke(messages)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what goes over the wire by installing a callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[chat_model][start] - prompts : You are a helpful assistant that translates English to French.\n",
      "[chat_model][start] - prompts : I love programming.\n",
      "\n",
      "=============\n",
      "[llm][end] - generation J'adore programmer.\n"
     ]
    }
   ],
   "source": [
    "#from lessons._lessonshelper.pretty_print_callback_handler import PrettyPrintCallbackHandler\n",
    "from _lessonshelper.pretty_print_callback_handler import PrettyPrintCallbackHandler\n",
    "\n",
    "pretty_print_callback = PrettyPrintCallbackHandler()\n",
    "\n",
    "chat = ChatOpenAI(callbacks=[pretty_print_callback])\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessage(content=\"I love programming.\")\n",
    "]\n",
    "answer = chat.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the combination of different type of messages using Chat Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "london-devops-VW7lFx7f-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
